{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1575,"sourceType":"datasetVersion","datasetId":854},{"sourceId":9875363,"sourceType":"datasetVersion","datasetId":6062750}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():\n    print(\"GPU trouvé :\", torch.cuda.get_device_name(0))\nelse:\n    print(\"Aucun GPU trouvé, utilisation du CPU.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pytorch mlp for binary classification\nfrom numpy import vstack\nfrom pandas import read_csv\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\nfrom torch import Tensor\nfrom torch.nn import Linear\nfrom torch.nn import ReLU\nfrom torch.nn import Sigmoid\nfrom torch.nn import Module\nfrom torch.optim import SGD\nfrom torch.nn import BCELoss\nfrom torch.nn.init import kaiming_uniform_\nfrom torch.nn.init import xavier_uniform_\nfrom tqdm import tqdm","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(os.listdir('../input/nyse'))","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plotScatterMatrix(df, plotSize, textSize):\n    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n    # Remove rows and columns that would lead to df being singular\n    df = df.dropna(axis=1)\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    columnNames = list(df)\n    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:10]\n    df = df[columnNames]\n    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n    corrs = df.corr().values\n    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Distribution graphs (histogram/bar graph) of column data\ndef plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n    for i in range(min(nCol, nGraphShown)):\n        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n        columnDf = df.iloc[:, i]\n        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n            valueCounts = columnDf.value_counts()\n            valueCounts.plot.bar()\n        else:\n            columnDf.hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.title(f'{columnNames[i]} (column {i})')\n    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n    plt.show()\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plotCorrelationMatrix(df, graphWidth):\n    # Check if the dataframe has a name attribute; otherwise, set a default name\n    filename = getattr(df, 'dataframeName')\n    \n    # Drop columns with NaN values and keep columns with more than one unique value\n    df = df.dropna(axis=1)\n    df = df[[col for col in df if df[col].nunique() > 1]]\n    \n    # Keep only numeric columns\n    df = df.select_dtypes(include=[np.number])\n\n    # If there are fewer than 2 numeric columns, exit\n    if df.shape[1] < 2:\n        print(f'No correlation plots shown: The number of non-NaN or constant numeric columns ({df.shape[1]}) is less than 2')\n        return\n\n    # Calculate correlation matrix\n    corr = df.corr()\n\n    # Plot correlation matrix with annotations\n    plt.figure(figsize=(graphWidth, graphWidth))\n    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True, cbar_kws={'shrink': .8})\n    plt.xticks(rotation=90)\n    plt.yticks(rotation=0)\n    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n    plt.show()\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's check 1st file: ../input/fundamentals.csv\n","metadata":{"editable":false}},{"cell_type":"code","source":"\n# fundamentals.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\ndf1 = pd.read_csv('../input/nyse/fundamentals.csv', delimiter=',')\ndf1.dataframeName = 'fundamentals.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df1.head()","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plotCorrelationMatrix(df1, 50)\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plotScatterMatrix(df1, 20, 10)\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndef remove_highly_correlated_columns(df, threshold=0.8):\n    # Compute the correlation matrix\n    df = df.select_dtypes(include=[np.number])\n\n    corr_matrix = df.corr().abs()  # Take absolute value to consider both positive and negative correlations\n    \n    # Select upper triangle of the correlation matrix\n    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n    \n    # Find index of columns with correlation greater than the threshold\n    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n    \n    # Drop the columns\n    df_reduced = df.drop(columns=to_drop)\n    \n    print(f\"Removed {len(to_drop)} columns with correlation above {threshold}.\")\n    return df_reduced\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_reduced=remove_highly_correlated_columns(df1)","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_reduced.shape","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df2 = pd.read_csv('../input/nyse/prices.csv', delimiter=',')\ndf2.dataframeName = 'prices.csv'\nnRow, nCol = df2.shape\nprint(f'There are {nRow} rows and {nCol} columns')","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df2.head()","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plotCorrelationMatrix(df2, 10)\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plotScatterMatrix(df2, 20, 7)\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prices-split-adjusted.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\ndf3 = pd.read_csv('../input/nyse/prices-split-adjusted.csv', delimiter=',',nrows = 200000)\ndf3.dataframeName = 'prices-split-adjusted.csv'\nnRow, nCol = df3.shape\nprint(f'There are {nRow} rows and {nCol} columns')","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df3.head()","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plotCorrelationMatrix(df3, 8)\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plotScatterMatrix(df3, 15, 10)\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null}]}